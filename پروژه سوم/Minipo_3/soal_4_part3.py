# -*- coding: utf-8 -*-
"""Soal_4_Part3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OEjaF0eir7gwlMShBRDmDpDuyXFJJGvE
"""

# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.model_selection import train_test_split
# set style of visualization
sns.set_style("whitegrid")
sns.set_palette("RdBu")

!pip install --upgrade --no-cache-dir gdown
!gdown 13UXkURa_S_QaHNsBO0m1UzbrVH1cakJK

data = pd.read_csv('/content/Life Expectancy Data.csv')
data.head()

# first i see some column name with empty space i will fixed it to ease of use
data.columns = data.columns.str.strip()

# Size of the data
data.shape

# A Quick Information about the Data
data.info()

# Checking for Null Values
data.isnull().sum()

# check if duplicated in data
data.duplicated().any()

# see quick info of numeric values
data.describe()

# see quick info of category values
data.describe(include = object)

# spliting data to train and test
train, test =  train_test_split(data, test_size = 0.2, random_state = 83)

def fill_train_with_median():
    return train.fillna(train.median(numeric_only = True))

def fill_test_with_median():
    return test.fillna(test.median(numeric_only = True))

# Apply the function to data
train = fill_train_with_median()
test = fill_test_with_median()

train.isna().sum()

plt.figure(figsize = (16,8))
sns.heatmap(train.select_dtypes(exclude = object).corr(), annot = True, fmt = ".2f", linewidths = 0.2)
plt.show()

# create object from labelencoder
encoder = LabelEncoder()
for column in ["Country", "Status"]:
    train[column] = encoder.fit_transform(train[column])
    test[column] = encoder.fit_transform(test[column])

X_train, y_train = train.drop(["Life expectancy"], axis=1).values, train[["Life expectancy"]].values
X_test, y_test = test.drop(["Life expectancy"], axis=1).values, test[["Life expectancy"]].values

# Scaling train data using min max scaler
scaler = MinMaxScaler()

X_train= scaler.fit_transform(X_train)
X_test= scaler.transform(X_test)

y_train

tree_model = tree.DecisionTreeRegressor(random_state=83)

# Fit the regressor to the training data
tree_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = tree_model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.metrics import r2_score


# Evaluate the model using metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print(f'Mean Absolute Error (MAE): {mae}')
print(f'Mean Squared Error (MSE): {mse}')

# Calculate R-squared
r2 = r2_score(y_test, y_pred)
print(f'R-squared (RÂ²): {r2}')

np.random.seed(53)
random_row = np.random.choice(X_test.shape[0], size=10, replace=False)
test2 = X_test[random_row]
label_test2 = y_test[random_row]
y_hat2 = tree_model.predict(test2)
label_test2, y_hat2
# delta = ((label_test2-y_hat2)/label_test2)
# # delta = np.vstack(("% of errore", delta))
# print(delta, "\n")

# label_test2 , y_hat2 = arrays_with_names = np.vstack(("prediction", label_test2)), np.vstack(("label", y_hat2))
# array = np.hstack((label_test2 , y_hat2))
# print(array)