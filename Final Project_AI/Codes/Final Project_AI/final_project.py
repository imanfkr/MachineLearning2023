# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zjiWYOjStC2Ls_ZUSUU6E6B542F1g1lD

## Import Libraries📕
"""

#libraries and tool importation
import numpy as np # linear algebra
import matplotlib.pylab as plt
from imblearn.under_sampling import RandomUnderSampler
import seaborn as sns

import pandas as pd # data processing
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM, Bidirectional
from tensorflow.keras.layers import Dropout
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from keras.layers import BatchNormalization, Dropout
from keras.layers import Dense, Activation
from tensorflow import keras

from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC

plt.rcParams["figure.figsize"] = (16,10) #Make the plots bigger by default
plt.rcParams["lines.linewidth"] = 2 #Setting the default line width
plt.style.use("ggplot")

"""## Install and Download Datasets📈"""

# install and Download Dataset (0)
!pip install --upgrade --no-cache-dir gdown
!gdown 1Ov_Qt87feNW9G9NkSHkIApXCemhOil6K
# install and Download Dataset (1)
!pip install --upgrade --no-cache-dir gdown
!gdown 1W4iNWqlZoLFGFPCrAba_jJQtZIwieqjf
# install and Download Dataset (2)
!pip install --upgrade --no-cache-dir gdown
!gdown 1VPWoQVzoqSk-5FJ9L-DESXLSirFwYIkj
# install and Download Dataset (3)
!pip install --upgrade --no-cache-dir gdown
!gdown 1rnewNPGctSsSqElVWoGkdWmO6O3Ze_nf

"""## Load Dataset📥"""

#original emg data
df0_emg = pd.read_csv("/content/0.csv", header=None )
df1_emg = pd.read_csv("/content/1.csv", header=None )
df2_emg = pd.read_csv("/content/2.csv", header=None )
df3_emg = pd.read_csv("/content/3.csv", header=None )
df_emg = pd.concat([df0_emg,df1_emg,df2_emg,df3_emg], axis = 0) #concatenate the dataframe
df0_emg , df1_emg , df2_emg , df3_emg , df_emg

"""##Display the combined dataset"""

df = df_emg
df.head() #print the first 5 rows of df

df.isnull().sum()

# Remove rows with any null values
# df.dropna(inplace=True)

df_emg.shape

# Create a 4x4 grid of subplots for various numerical variables
plt.figure(figsize=(120, 120))

plt.subplot(16,4,1)
sns.distplot(df[0], color="red").set_title('s1_1')

plt.subplot(16,4,2)
sns.distplot(df[1], color="green").set_title('s1_2')

plt.subplot(16,4,3)
sns.distplot(df[2], color="black").set_title('s1_3')

plt.subplot(16,4,4)
sns.distplot(df[3], color="blue").set_title('s1_4')

plt.subplot(16,4,5)
sns.distplot(df[4], color="red").set_title('s1_5')

plt.subplot(16,4,6)
sns.distplot(df[5], color="green").set_title('s1_6')

plt.subplot(16,4,7)
sns.distplot(df[6], color="black").set_title('s1_7')

plt.subplot(16,4,8)
sns.distplot(df[7], color="blue").set_title('s1_8')

plt.subplot(16,4,9)
sns.distplot(df[8], color="red").set_title('s2_1')

plt.subplot(16,4,10)
sns.distplot(df[9], color="green").set_title('s2_2')

plt.subplot(16,4,11)
sns.distplot(df[10], color="black").set_title('s2_3')

plt.subplot(16,4,12)
sns.distplot(df[11], color="blue").set_title('s2_4')

plt.subplot(16,4,13)
sns.distplot(df[12], color="red").set_title('s2_5')

plt.subplot(16,4,14)
sns.distplot(df[13], color="green").set_title('s2_6')

plt.subplot(16,4,15)
sns.distplot(df[14], color="black").set_title('s2_7')

plt.subplot(16,4,16)
sns.distplot(df[15], color="blue").set_title('s2_8')

plt.subplot(16,4,17)
sns.distplot(df[16], color="red").set_title('s3_1')

plt.subplot(16,4,18)
sns.distplot(df[17], color="green").set_title('s3_2')

plt.subplot(16,4,19)
sns.distplot(df[18], color="black").set_title('s3_3')

plt.subplot(16,4,20)
sns.distplot(df[19], color="blue").set_title('s3_4')

plt.subplot(16,4,21)
sns.distplot(df[20], color="red").set_title('s3_5')

plt.subplot(16,4,22)
sns.distplot(df[21], color="green").set_title('s3_6')

plt.subplot(16,4,23)
sns.distplot(df[22], color="black").set_title('s3_7')

plt.subplot(16,4,24)
sns.distplot(df[23], color="blue").set_title('s3_8')

plt.subplot(16,4,25)
sns.distplot(df[24], color="red").set_title('s4_1')

plt.subplot(16,4,26)
sns.distplot(df[25], color="green").set_title('s4_2')

plt.subplot(16,4,27)
sns.distplot(df[26], color="black").set_title('s4_3')

plt.subplot(16,4,28)
sns.distplot(df[27], color="blue").set_title('s4_4')

plt.subplot(16,4,29)
sns.distplot(df[28], color="red").set_title('s4_5')

plt.subplot(16,4,30)
sns.distplot(df[29], color="green").set_title('s4_6')

plt.subplot(16,4,31)
sns.distplot(df[30], color="black").set_title('s4_7')

plt.subplot(16,4,32)
sns.distplot(df[31], color="blue").set_title('s4_8')

plt.subplot(16,4,33)
sns.distplot(df[32], color="red").set_title('s5_1')

plt.subplot(16,4,34)
sns.distplot(df[33], color="green").set_title('s5_2')

plt.subplot(16,4,35)
sns.distplot(df[34], color="black").set_title('s5_3')

plt.subplot(16,4,36)
sns.distplot(df[35], color="blue").set_title('s5_4')

plt.subplot(16,4,37)
sns.distplot(df[36], color="red").set_title('s5_5')

plt.subplot(16,4,38)
sns.distplot(df[37], color="green").set_title('s5_6')

plt.subplot(16,4,39)
sns.distplot(df[38], color="black").set_title('s5_7')

plt.subplot(16,4,40)
sns.distplot(df[39], color="blue").set_title('s5_8')

plt.subplot(16,4,41)
sns.distplot(df[40], color="red").set_title('s6_1')

plt.subplot(16,4,42)
sns.distplot(df[41], color="green").set_title('s6_2')

plt.subplot(16,4,43)
sns.distplot(df[42], color="black").set_title('s6_3')

plt.subplot(16,4,44)
sns.distplot(df[43], color="blue").set_title('s6_4')

plt.subplot(16,4,45)
sns.distplot(df[44], color="red").set_title('s6_5')

plt.subplot(16,4,46)
sns.distplot(df[45], color="green").set_title('s6_6')

plt.subplot(16,4,47)
sns.distplot(df[46], color="black").set_title('s6_7')

plt.subplot(16,4,48)
sns.distplot(df[47], color="blue").set_title('s6_8')

plt.subplot(16,4,49)
sns.distplot(df[48], color="red").set_title('s7_1')

plt.subplot(16,4,50)
sns.distplot(df[49], color="green").set_title('s7_2')

plt.subplot(16,4,51)
sns.distplot(df[50], color="black").set_title('s7_3')

plt.subplot(16,4,52)
sns.distplot(df[51], color="blue").set_title('s7_4')

plt.subplot(16,4,53)
sns.distplot(df[52], color="red").set_title('s7_5')

plt.subplot(16,4,54)
sns.distplot(df[53], color="green").set_title('s7_6')

plt.subplot(16,4,55)
sns.distplot(df[54], color="black").set_title('s7_7')

plt.subplot(16,4,56)
sns.distplot(df[55], color="blue").set_title('s7_8')

plt.subplot(16,4,57)
sns.distplot(df[56], color="red").set_title('s8_1')

plt.subplot(16,4,58)
sns.distplot(df[57], color="green").set_title('s8_2')

plt.subplot(16,4,59)
sns.distplot(df[58], color="black").set_title('s8_3')

plt.subplot(16,4,60)
sns.distplot(df[59], color="blue").set_title('s8_4')

plt.subplot(16,4,61)
sns.distplot(df[60], color="red").set_title('s8_5')

plt.subplot(16,4,62)
sns.distplot(df[61], color="green").set_title('s8_6')

plt.subplot(16,4,63)
sns.distplot(df[62], color="black").set_title('s8_7')

plt.subplot(16,4,64)
sns.distplot(df[63], color="blue").set_title('s8_8')

"""## Preparation of emg-4 data

## Split the labels (y) from the emg data (x)
"""

X = df.loc[:,0:63]
y = df[64]
X , y

# Count the number of samples in each class
unique, counts = np.unique(y, return_counts=True)
print("Class counts before balancing:", dict(zip(unique, counts)))

# Use RandomUnderSampler to balance the classes
rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

# Count the number of samples in each class after balancing
unique_resampled, counts_resampled = np.unique(y_resampled, return_counts=True)
print("Class counts after balancing:", dict(zip(unique_resampled, counts_resampled)))
print('\n')
print("New balanced dataset shape:", X_resampled.shape, y_resampled.shape)

X = X_resampled
y = y_resampled
print(X.shape, y.shape)

"""## find the unique elements of y array🎯"""

y.unique()

"""## conversion to NumPy arrays"""

X = np.array(X)
y = np.array(y)
X , y

"""##subdivision in training and test set📊"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=83, stratify=y, shuffle=True)
X_train.shape , X_test.shape , y_train.shape , y_test.shape

"""## StandardScaler🧮"""

X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], 1) #m x n matrix --> column vector
X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], 1)
#x.shape[0] = number of rows in x
#x.shape[1] = number of columns in x

sc = StandardScaler() #select the scaler
X_train = sc.fit_transform(X_train) #fit and transform x_train
X_test = sc.transform(X_test) #transform x_test
X_train.shape , X_test.shape , y_train.shape , y_test.shape

X_train = X_train.reshape((-1, 8, 8))
X_test = X_test.reshape((-1, 8, 8))

print("Training set size")
print(X_train.shape)
print("Test set size")
print(X_test.shape)

y_train_categorical = np.eye(np.max(y_train) + 1)[y_train] #4x4 identical matrix indexed by y_train
#np.eye(np.max(y) + 1) -> 4x4 Id matrix (max(y) = 3)
y_train_categorical

print("Train Data size X and y")
print(X_train.shape)
print(y_train_categorical.shape)

print("Test Data size X and y")
print(X_test.shape)
print(y_test.shape)

"""## Recurrent NN🧬"""

model = Sequential()

model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 8)))
model.add(Dropout(0.2)) #dropout rate = 20%

model.add(LSTM(units = 50, return_sequences = True))
model.add(Dropout(0.2))

model.add(LSTM(units = 50, return_sequences = True))
model.add(Dropout(0.2))

model.add(LSTM(units = 50))
model.add(Dropout(0.2))

model.add(Dense(units = 64))
model.add(Dense(units = 128))

model.add(Dense(units = 4, activation="softmax")) #4 as the output classes
model.compile(optimizer = "adam" , loss = "categorical_crossentropy", metrics=["accuracy"]) #***

model.summary()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)

history=model.fit(X_train, y_train_categorical, epochs = 250, batch_size = 32, verbose=2 , callbacks=[callback],validation_split=0.2,)

"""## Accuracy📏"""

plt.figure(0)

plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()

"""## Loss during training📉"""

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

"""## RESULTS of NN📋"""

#calculate predictions
y_pred_categorical = model.predict(X_test)
#convert one hot vectors to prediction classes
y_pred = np.argmax(y_pred_categorical,axis = 1) #returns the index of the max element of each row of Y_pred
#-->returns values from 0 to 3
#confusion matrix
import seaborn as sns
confusion_mtx = confusion_matrix(y_test, y_pred)

#plot of the confusion matrix
f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

#print the classification report to evaluate the model
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""## SVM Classifier🎨"""

X_train_svm = X_train
y_train_svm = y_train
X_test_svm = X_test
y_test_svm = y_test

print("Train Data size x and y")
print(X_train_svm.shape)
print(y_train_svm.shape)

print("Test Data size x and y")
print(X_test_svm.shape)
print(y_test_svm.shape)

"""##  Install tslearn, the package containing TimeSeriesSVC"""

!pip install tslearn --upgrade --quiet

from tslearn.svm import TimeSeriesSVC

classifier = TimeSeriesSVC(kernel='linear',random_state = 93)
classifier.fit(X_train_svm,y_train_svm)
y_pred_svm_1 = classifier.predict(X_test_svm)

classifier = TimeSeriesSVC(kernel='rbf',random_state = 93)
classifier.fit(X_train_svm,y_train_svm)
y_pred_svm_2 = classifier.predict(X_test_svm)

classifier = TimeSeriesSVC(kernel='poly',random_state = 93)
classifier.fit(X_train_svm,y_train_svm)
y_pred_svm_3 = classifier.predict(X_test_svm)

classifier = TimeSeriesSVC(kernel='sigmoid',random_state = 93)
classifier.fit(X_train_svm,y_train_svm)
y_pred_svm_4 = classifier.predict(X_test_svm)

"""## RESULTS✅"""

from sklearn import metrics
#model accuracy
print("SVM classifier accuracy:",metrics.accuracy_score(y_test_svm, y_pred_svm_1))
print("SVM classifier accuracy:",metrics.accuracy_score(y_test_svm, y_pred_svm_2))
print("SVM classifier accuracy:",metrics.accuracy_score(y_test_svm, y_pred_svm_3))
print("SVM classifier accuracy:",metrics.accuracy_score(y_test_svm, y_pred_svm_4))

"""## confusion Matrix🎲"""

confusion_mtx = confusion_matrix(y_test_svm, y_pred_svm_3)

f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print('Classification report - SVM')
print(classification_report(y_test_svm, y_pred_svm_3))

"""## Random Forest Classifier"""

#mean extraction - training set
X_train_rf = np.empty((0,8)) #empty array of 8 columns
for i in range(0,X_train.shape[0]): #x_train.shape[0]
    matrix_8x8 = X_train[i]
    ch_means = matrix_8x8.mean(0) #mean for each channel in 8 timesteps
    X_train_rf = np.vstack((X_train_rf,ch_means))
print('X_train_rf size:')
print(X_train_rf.shape)

#mean extraction - test set
X_test_rf = np.empty((0,8)) #empty array of 8 columns
for i in range(0,X_test.shape[0]):
    matrix_8x8 = X_test[i]
    ch_means = matrix_8x8.mean(0) #mean for each channel in 8 timesteps
    X_test_rf = np.vstack((X_test_rf,ch_means))
print('X_test_rf size:')
print(X_test_rf.shape)

y_train_rf = y_train
y_test_rf = y_test

print('y_train_rf size:')
print(y_train_rf.shape)
print('y_test_rf size:')
print(y_test_rf.shape)

"""## Classifier and Prediction"""

#import the classifier
from sklearn.ensemble import RandomForestClassifier

#fit of the classifier to the training data
rf_model = RandomForestClassifier(n_estimators=100,random_state=93)
rf_model.fit(X_train_rf, y_train_rf)

#predictions
y_pred_rf = rf_model.predict(X_test_rf)

"""## RESULTS of Random Forest💾"""

# Model Accuracy
print("RandomForestClassifier accuracy:",metrics.accuracy_score(y_test_rf, y_pred_rf))

#confusion matrix
confusion_mtx = confusion_matrix(y_test_rf, y_pred_rf)
#plot
f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""## Accuracy"""

print('Classification report - Random Forest')
print(classification_report(y_test_rf, y_pred_rf))

"""## SVC Classifier🧩

## Reshaping Data
"""

import numpy as np

X_train = np.reshape(X_train, (X_train.shape[0], -1))
X_test = np.reshape(X_test, (X_test.shape[0], -1))

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, f1_score
model = SVC(kernel = 'rbf',decision_function_shape='ovo')
model.fit(X_train, y_train)
predictions = model.predict(X_test)
print(classification_report(y_test, predictions))

#confusion matrix
confusion_mtx = confusion_matrix(y_test, predictions)
#plot
f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""## Comparison of classification methods🎰"""

print('Classification report - Recurrent NN')
print(classification_report(y_test, y_pred))
print('--------------------------------------------------------')
print('Classification report - SVM')
print(classification_report(y_test_svm, y_pred_svm_3))
print('--------------------------------------------------------')
print('Classification report - Random Forest')
print(classification_report(y_test_rf, y_pred_rf))
print('--------------------------------------------------------')
print('Classification report - SVC')
print(classification_report(y_test, predictions))

"""## MLP🌡"""

model = MLPClassifier(hidden_layer_sizes=(80,), activation='relu', solver='adam',
                      alpha=0.1,max_iter=100, shuffle=True, random_state=93)

model.fit(X_train, y_train)
model.score(X_test, y_test)

predictions = model.predict(X_test)
#confusion matrix
confusion_mtx = confusion_matrix(y_test, predictions)
#plot
f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print(classification_report(y_test, predictions))

"""## **🔸 Decision Tree (sklearn)**"""

from sklearn.datasets import load_iris
from sklearn import tree

"""## Classification📚"""

clf = tree.DecisionTreeClassifier(max_depth=18, random_state=42, ccp_alpha=0.001)
clf.fit(X_train, y_train)

tree.plot_tree(clf)

"""#### * Predict📈"""

clf.predict(X_test)
clf.score(X_test, y_test)
clf.predict_proba(X_test)

y_pred = clf.predict(X_test)

confusion_mtx = confusion_matrix(y_test, y_pred)

f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print('Classification report - Decision tree')
print(classification_report(y_test, y_pred))

"""## NN Method⛓"""

from sklearn.neighbors import (NeighborhoodComponentsAnalysis,
KNeighborsClassifier)
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline

nca = NeighborhoodComponentsAnalysis(random_state=42)
knn = KNeighborsClassifier(n_neighbors=4)
nca_pipe = Pipeline([('nca', nca), ('knn', knn)])
nca_pipe.fit(X_train, y_train)
print(nca_pipe.score(X_test, y_test))

y_pred = nca_pipe.predict(X_test)

confusion_mtx = confusion_matrix(y_test, y_pred)

f,ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="Greens",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print('Classification report - Decision tree')
print(classification_report(y_test, y_pred))